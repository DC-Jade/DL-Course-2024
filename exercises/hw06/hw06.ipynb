{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6 - Experiments on MNIST for 10-class Classification\n",
    "\n",
    "Please implement the following three functions:\n",
    "- MnistMLP() - Design a 2-layer MLP\n",
    "- MnistCNN() - Design a 2-layer CNN \n",
    "\n",
    "Please train the 2-layer MLP and CNN models on the Mnist dataset and print the training results for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose,ToTensor,Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 1000\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# dataloader for the dataset\n",
    "def get_dataloader(train,batch_size=BATCH_SIZE):\n",
    "    transform_fn = Compose([\n",
    "        ToTensor(),\n",
    "        Normalize(mean = (0.1307,),std = (0.3081,))\n",
    "        ]) \n",
    "    dataset = MNIST(root = './data',train = train,transform = transform_fn, download = True)\n",
    "    data_loader = DataLoader(dataset,batch_size = batch_size,shuffle = True)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-lyer MLP \n",
    "class MnistMLP(nn.Module):\n",
    "    # Tip: write `def __init__(self)` and `def forward(self,input)`\n",
    "    # pass\n",
    "    def __init__(self):\n",
    "        super(MnistMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-lyer CNN\n",
    "class MnistCNN(nn.Module):\n",
    "    # Tip: write `def __init__(self)` and `def forward(self,input)`\n",
    "    # pass\n",
    "    def __init__(self):\n",
    "        super(MnistCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 64*7*7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistMLP().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, num_epochs):\n",
    "    data_loader = get_dataloader(True)\n",
    "    total_step = len(data_loader)\n",
    "    for idx, (input, target) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input.to(device))\n",
    "        loss = F.nll_loss(output, target.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (idx+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, idx+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    test_dataloader = get_dataloader(train = False,batch_size=TEST_BATCH_SIZE)\n",
    "    for idx,(input,target) in enumerate(test_dataloader):\n",
    "        with torch.no_grad():\n",
    "            output = model(input.to(device))\n",
    "            target = target.to(device)\n",
    "            cur_loss = F.nll_loss(output, target)\n",
    "            loss_list.append(cur_loss.cpu())\n",
    "            pred = output.max(dim = -1)[-1]\n",
    "            cur_acc = pred.eq(target).float().mean()\n",
    "            acc_list.append(cur_acc.cpu())\n",
    "    print(\"Mean accuracy: \", np.mean(acc_list), \"Mean loss: \", np.mean(loss_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fced3631f26548f5ac671065d52b27e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9912422 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0f2f337bdd437985b9ce2c421d29ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28881 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a181b845fa6d46d081aae84d1dc3efa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1648877 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53b90735c984e87b90da580efe1ffc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4542 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Mean accuracy:  0.0802 Mean loss:  0.00712392\n",
      "Epoch [1/3], Step [100/469], Loss: -1312.1116\n",
      "Epoch [1/3], Step [200/469], Loss: -6817.9761\n",
      "Epoch [1/3], Step [300/469], Loss: -16425.3398\n",
      "Epoch [1/3], Step [400/469], Loss: -30878.6719\n",
      "Epoch [2/3], Step [100/469], Loss: -63305.4766\n",
      "Epoch [2/3], Step [200/469], Loss: -92035.7656\n",
      "Epoch [2/3], Step [300/469], Loss: -120774.4141\n",
      "Epoch [2/3], Step [400/469], Loss: -148456.4688\n",
      "Epoch [3/3], Step [100/469], Loss: -210554.5625\n",
      "Epoch [3/3], Step [200/469], Loss: -253836.4688\n",
      "Epoch [3/3], Step [300/469], Loss: -291576.0000\n",
      "Epoch [3/3], Step [400/469], Loss: -358135.5938\n",
      "Mean accuracy:  0.0974 Mean loss:  -390300.1\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "num_epochs = 3\n",
    "for i in range(num_epochs):\n",
    "    train(i, num_epochs)\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistCNN().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy:  0.0766 Mean loss:  -0.0023528824\n",
      "Epoch [1/3], Step [100/469], Loss: -206188.0000\n",
      "Epoch [1/3], Step [200/469], Loss: -6746471.0000\n",
      "Epoch [1/3], Step [300/469], Loss: -46076316.0000\n",
      "Epoch [1/3], Step [400/469], Loss: -169745536.0000\n",
      "Epoch [2/3], Step [100/469], Loss: -783035840.0000\n",
      "Epoch [2/3], Step [200/469], Loss: -1505780224.0000\n",
      "Epoch [2/3], Step [300/469], Loss: -2828993536.0000\n",
      "Epoch [2/3], Step [400/469], Loss: -4365740544.0000\n",
      "Epoch [3/3], Step [100/469], Loss: -8771931136.0000\n",
      "Epoch [3/3], Step [200/469], Loss: -12989839360.0000\n",
      "Epoch [3/3], Step [300/469], Loss: -18487248896.0000\n",
      "Epoch [3/3], Step [400/469], Loss: -22285948928.0000\n",
      "Mean accuracy:  0.113500014 Mean loss:  -28374931000.0\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "num_epochs = 3\n",
    "for i in range(num_epochs):\n",
    "    train(i, num_epochs)\n",
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
